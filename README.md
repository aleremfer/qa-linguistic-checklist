# Checklist for Detecting Overreach in LLM Language Outputs

This repository provides a qualitative QA checklist for reviewing
LLM-generated content beyond surface-level fluency or correctness.

It is designed to help reviewers identify subtle failure modes such as:
- confidence miscalibration (over-assertive or unjustified certainty)
- semantic over-interpretation
- cultural and pragmatic misrecognition
- narrative or explanatory overreach
- hallucinations that remain unnoticed due to narrative or semantic coherence

The checklist is intended for evaluators, reviewers, and researchers
working with LLM outputs in real-world or culturally sensitive contexts.

Related work:
- See `hallucination-cases` for documented examples of epistemic and factual failures.
- See `prompt-eval-cases` for real-world prompts illustrating these issues in practice.

Reflections on these patterns are discussed in essays at:
https://open.substack.com/pub/alejandroremeseiro


